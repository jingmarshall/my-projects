{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-06-30T01:41:06.893491Z","iopub.execute_input":"2022-06-30T01:41:06.894428Z","iopub.status.idle":"2022-06-30T01:41:06.921169Z","shell.execute_reply.started":"2022-06-30T01:41:06.894322Z","shell.execute_reply":"2022-06-30T01:41:06.920342Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df_s1=pd.read_csv('/kaggle/input/friendsimdbratingprediction/friends_hackathon_zip (1)/friends_hackathon/season_01.csv')\ndf_s2=pd.read_csv('/kaggle/input/friendsimdbratingprediction/friends_hackathon_zip (1)/friends_hackathon/season_02.csv')\ndf_s3=pd.read_csv('/kaggle/input/friendsimdbratingprediction/friends_hackathon_zip (1)/friends_hackathon/season_03.csv')\ndf_s4=pd.read_csv('/kaggle/input/friendsimdbratingprediction/friends_hackathon_zip (1)/friends_hackathon/season_04.csv')\ndf_s5=pd.read_csv('/kaggle/input/friendsimdbratingprediction/friends_hackathon_zip (1)/friends_hackathon/season_05.csv')\ndf_s6=pd.read_csv('/kaggle/input/friendsimdbratingprediction/friends_hackathon_zip (1)/friends_hackathon/season_06.csv')\ndf_s7=pd.read_csv('/kaggle/input/friendsimdbratingprediction/friends_hackathon_zip (1)/friends_hackathon/season_07.csv')\ndf_s8=pd.read_csv('/kaggle/input/friendsimdbratingprediction/friends_hackathon_zip (1)/friends_hackathon/season_08.csv')\n\ndf_train=pd.read_csv('/kaggle/input/friendsimdbratingprediction/friends_hackathon_zip (1)/friends_hackathon/friends_train_ratings.csv')\ndf_test=pd.read_csv('/kaggle/input/friendsimdbratingprediction/friends_hackathon_zip (1)/friends_hackathon/friends_test_file.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:41:06.928410Z","iopub.execute_input":"2022-06-30T01:41:06.928983Z","iopub.status.idle":"2022-06-30T01:41:07.124100Z","shell.execute_reply.started":"2022-06-30T01:41:06.928948Z","shell.execute_reply":"2022-06-30T01:41:07.122536Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"# STEP 1:\n# We'll extract the 'title' from 'Transcripts' on df_s1, so we will connect df_s1 with df_train.\n# Also we will add length of 'Transcripts' from df_s1 on df_train,\n# so we will have the same format for df_train and df_test.\n\n# STEP 2:\n# For the episodes that have Part I and Part II, \n# it was combined in df_s1 and apart in df_train, \n# so we can either keep them apart to gain more accurate ratings, but need to separate them right,\n# or keep them combined with average ratings.\n# This notebook did the former.\n\n# STEP 3:\n# For the episodes that only exit in df_train but not in df_s1, \n# we can either delete them in df_train, or add empty rows into df_s1 and fillna later. \n# This notebook did the former.\n\n# STEP 4:\n# convert non-numerical values into numerical values,\n# like convert the date into the week of the year, all string into int(len of the string),\n# and the total_reviews to positive numerical values.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_transcripts_length(str):\n    return len(str)\n\ndef extract_title(str):\n    return str.split('\\n\\n\\n')[0].split(' (')[0].strip()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:41:08.226494Z","iopub.execute_input":"2022-06-30T01:41:08.227057Z","iopub.status.idle":"2022-06-30T01:41:08.234068Z","shell.execute_reply.started":"2022-06-30T01:41:08.227024Z","shell.execute_reply":"2022-06-30T01:41:08.232677Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_s1.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract info from df_s1,df_s2,df_s3\ndf_s1=df_s1.fillna('')\ndf_s1['transcripts_length']=df_s1['Transcripts'].apply(extract_transcripts_length)\ndf_s1['title']=df_s1['Transcripts'].apply(extract_title)\ndf_s1=df_s1.drop(['Unnamed: 0','Season','Episodes','Transcripts'],axis=1)\n#df_s1.tail()\n\ndf_s2=df_s2.fillna('')\ndf_s2['transcripts_length']=df_s2['Transcripts'].apply(extract_transcripts_length)\ndf_s2['title']=df_s2['Transcripts'].apply(extract_title)\ndf_s2=df_s2.drop(['Unnamed: 0','Season','Episodes','Transcripts'],axis=1)\n\ndf_s3=df_s3.fillna('')\ndf_s3['transcripts_length']=df_s3['Transcripts'].apply(extract_transcripts_length)\ndf_s3['title']=df_s3['Transcripts'].apply(extract_title)\ndf_s3=df_s3.drop(['Unnamed: 0','Season','Episodes','Transcripts'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:41:10.328680Z","iopub.execute_input":"2022-06-30T01:41:10.329116Z","iopub.status.idle":"2022-06-30T01:41:10.351614Z","shell.execute_reply.started":"2022-06-30T01:41:10.329084Z","shell.execute_reply":"2022-06-30T01:41:10.350498Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Extract info from df_s4\ndf_s4=df_s4.fillna('')\ndf_s4['transcripts_length']=df_s4['Transcripts'].apply(extract_transcripts_length)\ndf_s4['title']=df_s4['Transcripts'].apply(extract_title)\n\n# split part1 and part 2\npart1_length=len(df_s4['Transcripts'].iloc[-1].split('carrying a litter.\\nCommercial Break\\n')[0])\npart2_length=len(df_s4['Transcripts'].iloc[-1].split('carrying a litter.\\nCommercial Break\\n')[1])\n\ndf_s4=df_s4.drop(['Unnamed: 0','Season','Episodes','Transcripts'],axis=1)\n\ndf_s4.loc[22]=[part1_length,\"The One With Ross's Wedding Part I\"]\ndf_s4.loc[23]=[part2_length,\"The One With Ross's Wedding Part II\"]\n#df_s4.tail()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:41:16.624742Z","iopub.execute_input":"2022-06-30T01:41:16.625249Z","iopub.status.idle":"2022-06-30T01:41:16.649072Z","shell.execute_reply.started":"2022-06-30T01:41:16.625207Z","shell.execute_reply":"2022-06-30T01:41:16.647421Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Extract info from df_s5\ndf_s5=df_s5.fillna('')\ndf_s5['transcripts_length']=df_s5['Transcripts'].apply(extract_transcripts_length)\ndf_s5['title']=df_s5['Transcripts'].apply(extract_title)\n\n# split part1 and part 2\npart1_length=len(df_s5['Transcripts'].iloc[-2].split('Chandler turns and walks out.]\\n')[0])\npart2_length=len(df_s5['Transcripts'].iloc[-2].split('Chandler turns and walks out.]\\n')[1])\n\ndf_s5=df_s5.drop(['Unnamed: 0','Season','Episodes','Transcripts'],axis=1)\n\ndf_s5.loc[21]=[part1_length,\"The One In Vegas Part I\"]\ndf_s5.loc[22]=[part2_length,\"The One In Vegas Part II\"]","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:41:18.156290Z","iopub.execute_input":"2022-06-30T01:41:18.156675Z","iopub.status.idle":"2022-06-30T01:41:18.172332Z","shell.execute_reply.started":"2022-06-30T01:41:18.156644Z","shell.execute_reply":"2022-06-30T01:41:18.171040Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Extract info from df_s6\ndf_s6=df_s6.fillna('')\ndf_s6['transcripts_length']=df_s6['Transcripts'].apply(extract_transcripts_length)\ndf_s6['title']=df_s6['Transcripts'].apply(extract_title)\n\n# split part1 and part 2\npart1_length=len(df_s6['Transcripts'].loc[20].split('I still love you.\\nCommercial Break\\n')[0])\npart2_length=len(df_s6['Transcripts'].loc[20].split('I still love you.\\nCommercial Break\\n')[1])\n\ndf_s6=df_s6.drop(['Unnamed: 0','Season','Episodes','Transcripts'],axis=1)\n\ndf_s6.loc[20]=[part1_length,\"The One With The Proposal Part I\"]\ndf_s6.loc[21]=[part2_length,\"The One With The Proposal Part II\"]","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:41:19.640092Z","iopub.execute_input":"2022-06-30T01:41:19.641558Z","iopub.status.idle":"2022-06-30T01:41:19.657924Z","shell.execute_reply.started":"2022-06-30T01:41:19.641502Z","shell.execute_reply":"2022-06-30T01:41:19.656047Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Extract info from df_s7\ndf_s7=df_s7.fillna('')\ndf_s7['transcripts_length']=df_s7['Transcripts'].apply(extract_transcripts_length)\ndf_s7['title']=df_s7['Transcripts'].apply(extract_title)\n\n# split part1 and part 2\npart1_length=len(df_s7['Transcripts'].iloc[-1].split(\"she won’t be totally\\nalone.\")[0])\npart2_length=len(df_s7['Transcripts'].iloc[-1].split(\"she won’t be totally\\nalone.\")[1])\n\ndf_s7=df_s7.drop(['Unnamed: 0','Season','Episodes','Transcripts'],axis=1)\n\ndf_s7.loc[22]=[part1_length,\"The One With Chandler and Monica’s Wedding Part I\"]\ndf_s7.loc[23]=[part2_length,\"The One With Chandler and Monica’s Wedding Part II\"]","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:41:20.923901Z","iopub.execute_input":"2022-06-30T01:41:20.924328Z","iopub.status.idle":"2022-06-30T01:41:20.939966Z","shell.execute_reply.started":"2022-06-30T01:41:20.924296Z","shell.execute_reply":"2022-06-30T01:41:20.938826Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Extract info from df_s8\ndf_s8=df_s8.fillna('')\ndf_s8['transcripts_length']=df_s8['Transcripts'].apply(extract_transcripts_length)\ndf_s8['title']=df_s8['Transcripts'].apply(extract_title)\n\n# split part1 and part 2\npart1_length=len(df_s8['Transcripts'].loc[17].split('Sid you lucky deaf bastard.\\n')[0])\npart2_length=len(df_s8['Transcripts'].loc[17].split('Sid you lucky deaf bastard.\\n')[1])\n\ndf_s8=df_s8.drop(['Unnamed: 0','Season','Episodes','Transcripts'],axis=1)\n\ndf_s8.loc[17]=[part1_length,\"The One Where Rachel Has A Baby Part I\"]\ndf_s8.loc[18]=[part2_length,\"The One Where Rachel Has A Baby Part II\"]","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:41:22.358824Z","iopub.execute_input":"2022-06-30T01:41:22.359950Z","iopub.status.idle":"2022-06-30T01:41:22.373872Z","shell.execute_reply.started":"2022-06-30T01:41:22.359914Z","shell.execute_reply":"2022-06-30T01:41:22.372693Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df_s_combine=pd.concat([df_s1,df_s2,df_s3,df_s4,df_s5,df_s6,df_s7,df_s8],\n                       ignore_index=True)\n\nna_rows=df_s_combine.loc[df_s_combine['title']==''].index      # now we delete the na rows\ndf_s_combine=df_s_combine.drop(na_rows)\n\ndf_s_combine=df_s_combine.reset_index(drop='True')\ndf_s_combine.tail(5)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:41:38.308481Z","iopub.execute_input":"2022-06-30T01:41:38.308935Z","iopub.status.idle":"2022-06-30T01:41:38.335697Z","shell.execute_reply.started":"2022-06-30T01:41:38.308898Z","shell.execute_reply":"2022-06-30T01:41:38.334907Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Now working on the df_train.\n# We'll delete the episodes that only exit in df_train but not in df_s1.\ndf_train=df_train.drop([15,16,21,49,59,65,75,78,118,130,\n                        135,136,142,174,175,176,177,178,181,188,194])\ndf_train=df_train.reset_index(drop='True')\nprint(df_train.tail())","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:41:43.953945Z","iopub.execute_input":"2022-06-30T01:41:43.954312Z","iopub.status.idle":"2022-06-30T01:41:43.966977Z","shell.execute_reply.started":"2022-06-30T01:41:43.954282Z","shell.execute_reply":"2022-06-30T01:41:43.965563Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# We'll add length of 'Transcripts' from df_s1 on df_train\ndf_train['transcripts_length']=df_s_combine['transcripts_length']\n\n# convert the date into the week of the year\ndf_train['week of the year']=pd.to_datetime(df_train['date']).dt.week\n\n#convert string into int(len of the string)\nlength=[]\nfor i in range(174):\n    length.append(len(df_train['title'][i]))\ndf_train['title']=length\n\nlength=[]\nfor i in range(174):\n    length.append(len(df_train['plot'][i]))\ndf_train['plot']=length\n\n# change the total_reviews to positive numerical values\ndf_train['total_reviews']=[(-1*int(x.split(',')[0]))*1000+int(x.split(',')[1]) \n                             for x in df_train['total_reviews'].tolist()]\ndf_train=df_train.drop('date',axis=1)\ndf_train.tail()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:41:47.632445Z","iopub.execute_input":"2022-06-30T01:41:47.632843Z","iopub.status.idle":"2022-06-30T01:41:47.700712Z","shell.execute_reply.started":"2022-06-30T01:41:47.632808Z","shell.execute_reply":"2022-06-30T01:41:47.699580Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":" # Machine Learning on df_train","metadata":{}},{"cell_type":"code","source":"# Step 1:\n# Split data into features X and target y, \n# then split into train and test sets and do feature scaling.\n\n# Step 2:\n# Run different Regressors on the train data, get the R2 score,\n# and choose the 2 Regressors with the highest R2 scores.\n\n# Step 3:\n# Use VotingRegressor to ensemble on the 2 Regressors from Step 2,\n# it turns out to have a better R2 score than 2 Regressors alone.\n\n# Step 4:\n# So we got the algorithm to use for this project!!!","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate   \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:53:03.111597Z","iopub.execute_input":"2022-06-30T01:53:03.113059Z","iopub.status.idle":"2022-06-30T01:53:03.718501Z","shell.execute_reply.started":"2022-06-30T01:53:03.113022Z","shell.execute_reply":"2022-06-30T01:53:03.717204Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"X=df_train.drop('ratings',axis=1)\ny=df_train['ratings']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\npipe = Pipeline([('sscaler', StandardScaler())])  \nX_train=pipe.fit_transform(X_train)\nX_test=pipe.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:54:50.627529Z","iopub.execute_input":"2022-06-30T01:54:50.627980Z","iopub.status.idle":"2022-06-30T01:54:50.644988Z","shell.execute_reply.started":"2022-06-30T01:54:50.627906Z","shell.execute_reply":"2022-06-30T01:54:50.643359Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error\nN_neighbors=range(4,15,1)\nfor n_neighbors in N_neighbors:\n    reg=KNeighborsRegressor(n_neighbors=n_neighbors).fit(X_train,y_train)\n    MSE=round(mean_squared_error(y_true=y_test, y_pred=reg.predict(X_test), squared=True),3)\n    print(f'MSE score:{MSE},n_neighbors={n_neighbors},R2 score:{reg.score(X_test,y_test)}')\n# we'll settle with 'MSE score:0.134,n_neighbors=10,R2 score:0.126'","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:59:12.853040Z","iopub.execute_input":"2022-06-30T01:59:12.853527Z","iopub.status.idle":"2022-06-30T01:59:12.892817Z","shell.execute_reply.started":"2022-06-30T01:59:12.853493Z","shell.execute_reply":"2022-06-30T01:59:12.891253Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import ElasticNet\nnames=['Linear Regression','Lasso Reg','Ridge Reg','Elastic Net']\nfor model in [LinearRegression(),Lasso(), Ridge(),ElasticNet(l1_ratio=0.2),ElasticNet(l1_ratio=0.8)]:\n    model.fit(X_train,y_train)\n    print(model,round(model.score(X_test,y_test),3))\n# we'll settle with LinearRegression() 0.13   &   Ridge() 0.129","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:59:40.403308Z","iopub.execute_input":"2022-06-30T01:59:40.403684Z","iopub.status.idle":"2022-06-30T01:59:40.421889Z","shell.execute_reply.started":"2022-06-30T01:59:40.403653Z","shell.execute_reply":"2022-06-30T01:59:40.420235Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# This is the process of running different Regressors, but with bad results.\n# So we picked KNeighborsRegressor and LinearRegression.\n'''\nfrom sklearn.svm import SVR                    (R2 score:  0.096)\nfrom sklearn.model_selection import GridSearchCV\nparameters = {'kernel':['linear', 'poly', 'rbf', 'sigmoid'], 'C':[0.05,0.1,0.5]}\nsvr=SVR()\nclf = GridSearchCV(svr, param_grid=parameters)\nclf.fit(X_train,y_train)\nprint('R2 score: ',round(clf.best_estimator_.score(X_test,y_test),3))\n# it seems we will NOT use SVR (R2 score:  0.096)\n\n\nfrom sklearn.tree import DecisionTreeRegressor (R2 score:  -1.312)\ndtr=DecisionTreeRegressor()\ndtr.fit(X_train,y_train)\nprint('R2 score: ',round(dtr.score(X_test,y_test),3))\n# it seems we will NOT use DecisionTreeRegressor (R2 score:  -1.312)\n\nfrom sklearn.linear_model import SGDRegressor   (R2 score:  0.113)\nsgd=SGDRegressor()\nsgd.fit(X_train,y_train)\nprint('R2 score: ',round(sgd.score(X_test,y_test),3))\n# R2 score:  0.113\n\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets try ensemble knn & linear regression\nknn_reg=KNeighborsRegressor(n_neighbors=10)   # R2 score: 0.126\nlinear_reg=LinearRegression()                 # R2 score: 0.13 \n\nfrom sklearn.ensemble import VotingRegressor  # R2 score: 0.163 (better)\nvr = VotingRegressor([('knn_reg', knn_reg), ('linear_reg',linear_reg)])\nvr.fit(X_train,y_train)\nvr.score(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T01:59:49.859573Z","iopub.execute_input":"2022-06-30T01:59:49.859974Z","iopub.status.idle":"2022-06-30T01:59:49.977486Z","shell.execute_reply.started":"2022-06-30T01:59:49.859944Z","shell.execute_reply":"2022-06-30T01:59:49.976018Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# This is the process of using different ensembles, but with bad results.\n# So we picked VotingRegressor.\n'''\nfrom sklearn.ensemble import AdaBoostRegressor\nada_reg_knn_reg=AdaBoostRegressor(base_estimator=knn_reg, learning_rate=0.00009)\nada_reg_knn_reg.fit(X_train,y_train)\nada_reg_knn_reg.score(X_test,y_test)\n\nada_reg_linear_reg=AdaBoostRegressor(base_estimator=linear_reg, learning_rate=0.000001)\nada_reg_linear_reg.fit(X_train,y_train)\nada_reg_linear_reg.score(X_test,y_test)\n\nfrom sklearn.ensemble import GradientBoostingRegressor  # R2 score: -0.24 (NO)\ngrad_reg=GradientBoostingRegressor()\ngrad_reg.fit(X_train,y_train)\ngrad_reg.score(X_test,y_test)\n\nfrom sklearn.ensemble import StackingRegressor     # R2 score: 0.143\nestimators = [('knn_reg', knn_reg),('linear_reg', linear_reg)]\n\nsta_reg = StackingRegressor(estimators=estimators)\nsta_reg .fit(X_train,y_train)\nsta_reg .score(X_test,y_test)\n\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's get the final result.","metadata":{}},{"cell_type":"code","source":"# Step 1:\n# Data Preparation like above (Convert everything into numerical values,\n                                # and use the same pipleine above for feature scaling).\n\n# Step 2:\n# Run the VotingRegressor on df_test to get the final result!\n\n# Step 3:\n# Turn the fianl result into csv file","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert 'date' into 'week of the year'.\ndf_test['week of the year']=pd.to_datetime(df_test['date']).dt.week\n# Cnovert string into int(len of the string).\nlength=[]\nfor i in range(len(df_test['title'])):\n    length.append(len(df_test['title'][i]))\ndf_test['title']=length\n\nlength=[]\nfor i in range(len(df_test['plot'])):\n    length.append(len(df_test['plot'][i]))\ndf_test['plot']=length\n\nlength=[]\nfor i in range(len(df_test['Transcripts'])):\n    length.append(len(df_test['Transcripts'][i]))\ndf_test['Transcripts']=length\n\n# change the total_reviews to positive\ndf_test['total_reviews']=[(-1*int(x.split(',')[0]))*1000+int(x.split(',')[1]) \n                             for x in df_test['total_reviews'].tolist()]\n\ndf_test=df_test.drop(['date','ID'],axis=1)\ndf_test.tail()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T02:06:09.076623Z","iopub.execute_input":"2022-06-30T02:06:09.077100Z","iopub.status.idle":"2022-06-30T02:06:09.116550Z","shell.execute_reply.started":"2022-06-30T02:06:09.077065Z","shell.execute_reply":"2022-06-30T02:06:09.115343Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"new_X_test=df_test.drop('ratings',axis=1)\nnew_X_test=pipe.transform(new_X_test)\npredictions=vr.predict(new_X_test)\nID=range(1,36)\ndf_final=pd.DataFrame()\ndf_final['ID']=ID\ndf_final['ratings']=predictions\nprint(df_final)\ndf_final.to_csv('Friends_Rating_Prediction.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T02:08:35.765942Z","iopub.execute_input":"2022-06-30T02:08:35.766659Z","iopub.status.idle":"2022-06-30T02:08:35.788984Z","shell.execute_reply.started":"2022-06-30T02:08:35.766624Z","shell.execute_reply":"2022-06-30T02:08:35.787905Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"##### ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}